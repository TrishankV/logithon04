{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  \n",
    "import json\n",
    "import spacy\n",
    "from gliner_spacy.pipeline import GlinerSpacy\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load T5 model for text structuring\n",
    "model_name = \"t5-base\"  # You can experiment with different T5 models\n",
    "t5_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load zero-shot classification pipeline with BART\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define entity labels for zero-shot classification\n",
    "LABELS = [\"INVOICE_NUMBER\", \"DATE\", \"TOTAL_AMOUNT\", \"COMPANY_NAME\", \"ADDRESS\"]\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts raw text from a PDF file.\"\"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def structure_text_with_t5(raw_text):\n",
    "    \"\"\"Structures raw text into sentences using T5 model.\"\"\"\n",
    "    input_text = f\"structure: {raw_text}\"\n",
    "    input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    outputs = t5_model.generate(input_ids)\n",
    "    structured_text = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return structured_text\n",
    "\n",
    "def extract_entities_zero_shot(text):\n",
    "    \"\"\"Extracts entities from text using zero-shot classification.\"\"\"\n",
    "    sentences = text.split(\". \")  # Assuming sentences end with '. '\n",
    "    entities = []\n",
    "    for sentence in sentences:\n",
    "        results = classifier(sentence, LABELS)\n",
    "        top_label = results[\"labels\"][0]\n",
    "        top_score = results[\"scores\"][0]\n",
    "        if top_score > 0.7:  # Adjust threshold as needed\n",
    "            start_char = sentence.find(results[\"sequence\"])\n",
    "            end_char = start_char + len(results[\"sequence\"])\n",
    "            entities.append((results[\"sequence\"], top_label, start_char, end_char))\n",
    "    return entities\n",
    "\n",
    "def extract_entities_ner(text, ner_model):\n",
    "    \"\"\"Extracts entities from text using a trained NER model (optional).\"\"\"\n",
    "    doc = ner_model(text)\n",
    "    entities = [(ent.text, ent.label_, ent.start_char, ent.end_char) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "def process_pdf(pdf_path, use_ner=False):\n",
    "    \"\"\"Processes a PDF file, extracts entities, and returns a structured dictionary.\"\"\"\n",
    "    raw_text = extract_text_from_pdf(pdf_path)\n",
    "    structured_text = structure_text_with_t5(raw_text)\n",
    "\n",
    "    if use_ner and nlp:\n",
    "        entities = extract_entities_ner(structured_text, nlp)\n",
    "    else:\n",
    "        entities = extract_entities_zero_shot(structured_text)\n",
    "\n",
    "    # Organize extracted entities into a dictionary\n",
    "    extracted_data = {}\n",
    "    for entity_text, entity_type, start, end in entities:\n",
    "        if entity_type not in extracted_data:\n",
    "            extracted_data[entity_type] = []\n",
    "        extracted_data[entity_type].append(entity_text)\n",
    "\n",
    "    return extracted_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373b5cf7aae5451aa5be4148c5fe81e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/789 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b290a0cad0c44e008fa23ef2a14b38c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/511M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b81348597341c8881ddef76f15939c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/315 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e5b2a00f524a15ae22bb6102b4f9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09b36820ef74cdf8e46b35d09e33c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b4e321d31a49669213619aa20988dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f582c5b31e244628b077ac66f4b62a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/PIL/Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9726561307907104, 'answer': '$ 3,980', 'start': 11, 'end': 12}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\n",
    "    \"document-question-answering\",\n",
    "    model=\"impira/layoutlm-document-qa\",\n",
    ")\n",
    "\n",
    "nlp(\n",
    "    \"https://templates.invoicehome.com/invoice-template-us-neat-750px.png\",\n",
    "    \"What is the invoice number?\"\n",
    ")\n",
    "# {'score': 0.9943977, 'answer': 'us-001', 'start': 15, 'end': 15}\n",
    "\n",
    "nlp(\n",
    "    \"https://miro.medium.com/max/787/1*iECQRIiOGTmEFLdWkVIH2g.jpeg\",\n",
    "    \"What is the purchase amount?\"\n",
    ")\n",
    "# {'score': 0.9912159, 'answer': '$1,000,000,000', 'start': 97, 'end': 97}\n",
    "\n",
    "nlp(\n",
    "    \"https://www.accountingcoach.com/wp-content/uploads/2013/10/income-statement-example@2x.png\",\n",
    "    \"What are the 2020 net sales?\"\n",
    ")\n",
    "# {'score': 0.59147286, 'answer': '$ 3,750', 'start': 19, 'end': 20}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
